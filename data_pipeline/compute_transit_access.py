# data_pipeline/compute_transit_access.py
# Transit Access (Toronto) = nearest distance to (surface GTFS stops + OSM subway stations)
# Outputs: web/public/neighbourhood_transit_scores.geojson

import zipfile
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from shapely.strtree import STRtree

ROOT = Path(__file__).resolve().parents[1]

# Inputs
SURFACE_GTFS_ZIP = ROOT / "data_pipeline" / "data" / "ttc_gtfs.zip"                 # you already have this
OSM_SUBWAY_GEOJSON = ROOT / "data_pipeline" / "data" / "ttc_subway_osm.geojson"     # generated by fetch_subway_osm.py
NBH_GEOJSON = ROOT / "web" / "public" / "toronto_neighbourhoods.geojson"

# Outputs
OUT_DIR = ROOT / "data_pipeline" / "output"
OUT_DIR.mkdir(parents=True, exist_ok=True)

OUT_GEOJSON = OUT_DIR / "neighbourhood_transit_scores.geojson"
OUT_WEB_COPY = ROOT / "web" / "public" / "neighbourhood_transit_scores.geojson"


def pick_name_col(gdf: gpd.GeoDataFrame) -> str:
    for c in ["neighbourhood_name", "AREA_NAME", "NAME", "Neighbourhood", "NEIGH_NAME", "NEIGHBOURHOOD_NAME"]:
        if c in gdf.columns:
            return c
    non_geom = [c for c in gdf.columns if c != "geometry"]
    return non_geom[0] if non_geom else "geometry"


def distance_to_score(dist_m: np.ndarray) -> np.ndarray:
    """
    Interpretable scoring (policy-friendly):
      0m -> 100
      2000m+ -> 0
    """
    max_dist = 2000.0
    scaled = np.clip(dist_m / max_dist, 0, 1)
    return np.round((1.0 - scaled) * 100.0, 1)


def read_stops_from_gtfs_zip(zip_path: Path) -> pd.DataFrame:
    with zipfile.ZipFile(zip_path, "r") as z:
        with z.open("stops.txt") as f:
            df = pd.read_csv(f)

    if not {"stop_lat", "stop_lon"}.issubset(df.columns):
        raise ValueError(f"{zip_path.name}: stops.txt missing stop_lat/stop_lon")

    keep = [c for c in ["stop_id", "stop_name", "stop_lat", "stop_lon"] if c in df.columns]
    df = df[keep].copy()

    # Basic cleaning
    df = df.dropna(subset=["stop_lat", "stop_lon"])
    # Drop duplicate coordinate points (many platforms share ids/variants)
    df = df.drop_duplicates(subset=["stop_lat", "stop_lon"])

    return df


def main():
    # --- file checks ---
    if not NBH_GEOJSON.exists():
        raise FileNotFoundError(f"Missing neighbourhood GeoJSON: {NBH_GEOJSON}")

    if not SURFACE_GTFS_ZIP.exists():
        raise FileNotFoundError(f"Missing surface GTFS zip: {SURFACE_GTFS_ZIP}")

    if not OSM_SUBWAY_GEOJSON.exists():
        raise FileNotFoundError(
            f"Missing OSM subway stations file: {OSM_SUBWAY_GEOJSON}\n"
            "Run: python data_pipeline/fetch_subway_osm.py"
        )

    # --- 1) Load neighbourhood polygons ---
    nbh = gpd.read_file(NBH_GEOJSON)
    if nbh.crs is None:
        nbh = nbh.set_crs(epsg=4326)
    else:
        nbh = nbh.to_crs(epsg=4326)

    name_col = pick_name_col(nbh)

    # Representative points stay inside polygon (better than centroid)
    nbh_points = gpd.GeoDataFrame(
        nbh[[name_col]].copy(),
        geometry=nbh.geometry.representative_point(),
        crs="EPSG:4326",
    )

    # --- 2) Load surface stops from GTFS ---
    stops_df = read_stops_from_gtfs_zip(SURFACE_GTFS_ZIP)
    surface_geom = [Point(xy) for xy in zip(stops_df["stop_lon"], stops_df["stop_lat"])]
    surface_stops = gpd.GeoDataFrame(stops_df, geometry=surface_geom, crs="EPSG:4326")[["geometry"]].copy()

    # --- 3) Load subway stations from OSM (GeoJSON points) ---
    subway = gpd.read_file(OSM_SUBWAY_GEOJSON)
    subway = subway.to_crs(epsg=4326)
    subway = subway[["geometry"]].copy()

    # Keep only point geometries (defensive)
    subway = subway[subway.geometry.geom_type == "Point"].copy()

    # --- 4) Merge stops ---
    all_stops = gpd.GeoDataFrame(
        pd.concat([surface_stops, subway], ignore_index=True),
        geometry="geometry",
        crs="EPSG:4326",
    )

    # Deduplicate merged stops by coordinates
    all_stops["lon"] = all_stops.geometry.x.round(6)
    all_stops["lat"] = all_stops.geometry.y.round(6)
    all_stops = all_stops.drop_duplicates(subset=["lon", "lat"]).drop(columns=["lon", "lat"])

    print("Surface stops:", len(surface_stops))
    print("Subway stations (OSM):", len(subway))
    print("Total unique stop points used:", len(all_stops))

    # --- 5) Project to meters for distance calculations ---
    # EPSG:26917 (UTM 17N) is good for Toronto distances
    nbh_m = nbh.to_crs(epsg=26917)
    nbh_points_m = nbh_points.to_crs(epsg=26917)
    stops_m = all_stops.to_crs(epsg=26917)

    # --- 6) Nearest stop distance using STRtree (Shapely 2 safe) ---
    stop_geoms = list(stops_m.geometry.values)
    tree = STRtree(stop_geoms)

    # query_nearest returns indices; NOT guaranteed to match input order -> map back
    (idx_left, _idx_right), dist = tree.query_nearest(
        nbh_points_m.geometry.values,
        return_distance=True
    )

    dists = np.empty(len(nbh_points_m), dtype=float)
    dists[idx_left] = np.array(dist, dtype=float)  # meters

    # --- 7) Build output GeoJSON ---
    out = nbh_m.copy()
    out["neighbourhood_name"] = nbh[name_col].astype(str).values
    out["transit_dist_m"] = np.round(dists, 1)
    out["transit_score"] = distance_to_score(dists)

    # back to WGS84 for web maps
    out = out.to_crs(epsg=4326)

    # --- 8) Save ---
    out.to_file(OUT_GEOJSON, driver="GeoJSON")
    out.to_file(OUT_WEB_COPY, driver="GeoJSON")

    print("✅ Saved:", OUT_GEOJSON)
    print("✅ Copied for web:", OUT_WEB_COPY)
    print("\nAttribution to include in your app:")
    print(' - Contains information licensed under the Open Government Licence - Toronto')
    print(' - © OpenStreetMap contributors')


if __name__ == "__main__":
    main()
